\section{Porównanie zastosowanych metod wykrywania za³amków R \small{(autor: Jakub Wojtalewicz)}}\label{sczyty-eksperyment}
\subsection{Wprowadzenie}
Celem niniejszego eksperymentu jest ocena skutecznoœci zastosowanych w pracy
metod wykrywania za³amków R w sygnale EKG w danych pochodz¹cych z urz¹dzenia
Polar H10. Porównania dokonano zarówno na danych dobrej jakoœæ, o niskim
poziomie zak³óceñ, jak i na sygnale mniej czystym, charakteryzuj¹cym siê
wiêksz¹ nieprzewidywalnoœci¹.
\subsection{Definicja miar do analizy wyników}
Analizê wyników przeprowadzono na podstawie miar takich jak czu³oœæ (recall),
precyzja (precision), oraz ich œrednia harmoniczna, czyli F1. Miary te obliczne
s¹ na podstawie wartoœci TP (True Positive), FP (False Positive), oraz FN
(False Negative). Sposób obliczania oraz krótki opis wspomnianych metryk
znajduje siê poni¿ej:
\begin{itemize}
    \item \textbf{TP (True Positive)} -- liczba przypadków, w których model prawid³owo rozpozna³ za³amki R
    \item \textbf{FP (False Positive)} -- liczba przypadków, w których model b³êdnie zaklasyfikowa³ fragment sygna³u jako sczyt R
    \item \textbf{FN (False Negative)} -- liczba przypadków, w których model nie rozpozna³ rzeczywistego za³amka R.
    \item \textbf{Czu³oœæ (Recall)} -- wskazuje, jaka czêœæ rzeczywistych pozytywnych przypadków zosta³a poprawnie rozpoznana:
          \begin{equation}
              \text{Recall} = \frac{TP}{TP + FN}
          \end{equation}

    \item \textbf{Precyzja (Precision)} – wskazuje, jaka czêœæ rozpoznanych pozytywnych przypadków jest rzeczywiœcie poprawna:
          \begin{equation}
              \text{Precision} = \frac{TP}{TP + FP}
          \end{equation}

    \item \textbf{F1} – œrednia harmoniczna czu³oœci i precyzji, która daje zbalansowan¹ miarê tych dwóch wskaŸników:
          \begin{equation}
              F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
          \end{equation}
\end{itemize}

\subsection{Trening modelu}
Przeprowadzono trening dwóch wariantów modelu sieci UNet. Pierwszy wariant
wytrenowano na danych pacjentów ze zbioru MIT-BIH, a drugi na zbiorze MIT-BIH
Noise Stress, który zawiera dane wybranych pacjentów z pierwotnego zbioru,
wzbogacone o szum oraz zjawisko dryfu linii izoelektrycznej (baseline wander).
Oba zbiory zawieraj¹ adnotacje dotycz¹ce lokalizacji szczytów R. Do treningu i
oceny wydajnoœci sieci UNet zastosowano okna o d³ugoœci 10 sekund, poniewa¿ w
trakcie fazy projektowej taki rozmiar wykazywa³ najwy¿sz¹ skutecznoœæ. Modele
by³y trenowane przez 30 epok, przy u¿yciu funkcji straty Binary Crossentropy
oraz optymalizatora Adam do dostosowywania wag modelu.

Po wytrenowaniu modeli przeprowadzono ich ewaluacjê na tych samych zbiorach
danych, na których by³y trenowane, porównuj¹c wyniki klasyfikacji z
oznaczeniami wykonanymi przez specjalistów. Wstêpne rezultaty przedstawiono w
tabeli \ref{wyniki1}.
\begin{table}[ht]
    \captionsetup{justification=centering}
    \caption{Wyniki pierwszego testu modeli na zbiorach treningowych (zaokr¹glone do 3 miejsc dziesiêtnych)}
    \centering
    \begin{tabular}{|l|c|c|}
        \hline
        \multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{\textbf{MIT-BIH}} & \multicolumn{1}{c|}{\textbf{MIT-BIH Noise Stress}} \\
        \hline
        TP                     & $33436$                               & $5801$                                             \\
        \hline
        FP                     & $76273$                               & $19992$                                            \\
        \hline
        FN                     & $79211$                               & $20569$                                            \\
        \hline
        Recall                 & $0,297$                               & $0,220$                                            \\
        \hline
        Precision              & $0,305$                               & $0,225$                                            \\
        \hline
        F1                     & $0,301$                               & $0,222$                                            \\
        \hline
    \end{tabular}
    \label{wyniki1}
\end{table}
Otrzymane wyniki by³y zaskakuj¹ce, co sk³oni³o do dok³adniejszej analizy przyczyn b³êdów w
postaci graficznej. Inspekcja wizualna ujawni³a przesuniêcie wielu etykiet
wzglêdem rzeczywistych maksimów sygna³u, co by³o trudne do wyjaœnienia.
Przyk³ad tego zjawiska zaprezentowano na Rys. \ref{fig/zleEtykietyMit}. Na wykresie ¿ó³te znaczniki reprezentuj¹ pozycje szczytów wed³ug etykiet, niebieskie wskazuj¹ miejsca, gdzie model rozpozna³ szczyty, natomiast czerwone oznaczaj¹ punkty, w których etykiety pokrywaj¹ siê z detekcjami dokonanymi przez model

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{Rysunki/nieprecyzyjne etykiety.png}
    \caption{Przyk³ad nieprecyzyjnych etykiet w zbiorze MIT-BIH.}
    \label{fig/zleEtykietyMit}
\end{figure}

W wielu przypadkach etykiety by³y nieznacznie przesuniête wzglêdem
rzeczywistego szczytu, czêsto o kilka próbek, podczas gdy szczyty przewidywane
przez sieæ charakteryzowa³y siê wiêksz¹ precyzj¹. Aby umo¿liwiæ bardziej
adekwatn¹ analizê wyników, uwzglêdniaj¹c¹ rzeczywist¹ jakoœæ przewidywañ,
wprowadzono tolerancjê wynosz¹c¹ 30 ms. Rozpoznanie szczytu w odleg³oœci do 30
ms od etykiety uznano za prawdziwie pozytywne (TP). Wyniki po zastosowaniu
tolerancji przedstawiono w tabeli \ref{wyniki2}, a tak¿e graficznie na Rys.
\ref{fig/poprawioneEtykietyMit}, gdzie ró¿owy kolor znacznika oznacza punkty
wykryte w granicach przyjêtej tolerancji.

\begin{table}[ht]
    \captionsetup{justification=centering}
    \caption{Wyniki drugiego testu modeli na zbiorach treningowych - po wprowadzeniu tolerancji (zaokr¹glone do 3 miejsc dziesiêtnych)}
    \centering
    \begin{tabular}{|l|c|c|}
        \hline
        \multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{\textbf{MIT-BIH}} & \multicolumn{1}{c|}{\textbf{MIT-BIH Noise Stress}} \\
        \hline
        TP                     & $105183$                              & $24341$                                            \\
        \hline
        FP                     & $4526$                                & $1453$                                             \\
        \hline
        FN                     & $7464$                                & $2029$                                             \\
        \hline
        Recall                 & $0,934$                               & $0,923$                                            \\
        \hline
        Precision              & $0,959$                               & $0,944$                                            \\
        \hline
        F1                     & $0,946$                               & $0,933$                                            \\
        \hline
    \end{tabular}
    \label{wyniki2}
\end{table}
\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.5]{Rysunki/etykiety z tolerancja.png}
    \caption{Wyniki klasyfikacji po wprowadzeniu tolerancji}
    \label{fig/poprawioneEtykietyMit}
\end{figure}

\subsection{Zastosowanie modeli na danych z Polar H10}
Dane w zbiorach MIT-BIH zosta³y zarejestrowane z czêstotliwoœci¹ próbkowania
360 Hz, natomiast dane z czujnika Polar H10 s¹ zbierane z czêstoœci¹ 130 Hz.
Aby umo¿liwiæ wykorzystanie modeli wytrenowanych na danych o innej
czêstotliwoœci próbkowania ni¿ dane testowe, mo¿na zastosowaæ jedno z dwóch
podejœæ. Pierwsze polega na redukcji czêstotliwoœci wy¿szego próbkowania do
ni¿szego poprzez decymacjê, co wi¹¿e siê z utrat¹ czêœci szczegó³owoœci danych.
Drugie podejœcie zak³ada zwiêkszenie czêstotliwoœci próbkowania zbioru o
ni¿szej czêstotliwoœci, na przyk³ad poprzez interpolacjê. W niniejszym
eksperymencie zastosowano drugie podejœcie – dane z czujnika Polar H10 poddano
interpolacji liniowej do 360 Hz, z wykorzystaniem funkcji \emph{interp1d} z
modu³u \emph{scipy.interpolate}.

\subsection{Analiza danych wysokiej jakoœci}
W trakcie analizy danych pozbawionych zak³óceñ przeprowadzono empiryczn¹ ocenê
algorytmu Pan-Tompkinsa, który wykaza³ siê bardzo wysok¹ skutecznoœci¹. W
analizowaym 24-godzinnym fragmencie danych zaobserwowano jedynie sporadyczne
przypadki fa³szywie negatywne (FN), co przek³ada sie na ponad 99\% trafnych
klasyfikacji. Z tego wzglêdu algorytm Pan-Tompkinsa zosta³ uznany za „z³oty
standard” w tym przypadku, wzglêdem którego oceniono wydajnoœæ modeli UNet.
Wyniki porównania modeli z wynikami algorytmu Pan-Tompkinsa dla 24 godzinnej
próbki z urz¹dzenia Polar H10 przedstawiono w tabeli \ref{wynikiClearUnet}. Na
podstawie przeprowadzonej analizy stwierdzono, ¿e oba algorytmy bardzo dobrze
radz¹ sobie z sygna³em wysokiej jakoœci.

\begin{table}[ht]
    \captionsetup{justification=centering}
    \caption{Wyniki klasyfikacji wariantów sieci UNet wzglêdem wartoœci wyznaczonych przez algorytm Pan-Tompkins dla 24 godzinnego odcinka danych (zaokr¹glone do 3 miejsc dziesiêtnych)}
    \centering
    \begin{tabular}{|l|c|c|}
        \hline
        \multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{\textbf{MIT-BIH}} & \multicolumn{1}{c|}{\textbf{MIT-BIH Noise Stress}} \\
        \hline
        TP                     & $93903$                               & $93899$                                            \\
        \hline
        FP                     & $16$                                  & $95$                                               \\
        \hline
        FN                     & $83$                                  & $87$                                               \\
        \hline
        Recall                 & $>0.999$                              & $0,999$                                            \\
        \hline
        Precision              & $>0.999$                              & $0,999$                                            \\
        \hline
        F1                     & $>0.999$                              & $0,999$                                            \\
        \hline
    \end{tabular}
    \label{wynikiClearUnet}
\end{table}

\subsection{Analiza danych zaszumionych}
% W przypadku danych zaszumionych empiryczna ocena wykaza³a liczne nieprawid³owoœci w dzia³aniu algorytmu Pan-Tompkinsa. Przyk³ad b³êdnego dzia³ania algorytmu przedstawiono na Rys. ref{rys1}. Z tego powodu, w celu okreœlenia skutecznoœci algorytmów przeprowadzono rêczne etykietowanie fragmentu danych z czujnika Polar H10. Nale¿y jednak zaznaczyæ, ¿e etykietyzacja nie zosta³a przeprowadzono przez specjalistê, z potwierdzon¹ wiedz¹ medyczn¹, a przez autorów niniejszej pracy, tzn. studentów kierunku informatycznego, co mog³o wp³yn¹c na jakoœæ etykiet.

W przypadku danych zaszumionych manualna ocena wykaza³a liczne
nieprawid³owoœci w dzia³aniu algorytmu Pan-Tompkinsa. Problemy te wynika³y
g³ównie z obecnoœci zak³óceñ, takich jak szum czy dryf linii izoelektrycznej
(baseline wander), które znacz¹co utrudnia³y prawid³owe wykrywanie za³amków R.
Przyk³ad b³êdnego dzia³ania algorytmu przedstawiono na Rys.
\ref{fig/zaszumionyTompkins}, gdzie zauwa¿alne jest pomijanie istotnych
szczytów sygna³u.

\begin{figure}[ht]
    \centering
    % \includegraphics[scale=0.5]{Rysunki/faultyPanTompkins.png}
    \includegraphics[width=\textwidth]{Rysunki/pt_unet_comparison.png}
    % \caption{Fragment zaszumionego sygna³u EKG, na którym Algorytm Pan-Tompkins nie wykry³ wszystkich szczytów R}
    \caption{Porównanie wykrywania szczytów R na przyk³adzie zaszumionego fragmentu sygna³u EKG, z zastosowaniem algorytmu Pan-Tompkinsa oraz wariantu sieci UNet.}
    \label{fig/zaszumionyTompkins}
\end{figure}

W celu przeprowadzenia oceny skutecznoœci zastosowanych podejœæ, dokonano
rêcznego oznaczenia fragmentu danych pochodz¹cego z czujnika Polar H10. Nale¿y
zaznaczyæ, ¿e etykietyzacja nie zosta³a przeprowadzona przez specjalistê, z
potwierdzon¹ wiedz¹ medyczn¹, a przez autorów niniejszej pracy, co mog³o
wp³yn¹c na jakoœæ samych etykiet.

Wyniki dzia³ania poszczególnych algorytmów uzyskane na oznaczonym fragmencie
danych przedstawiono w tabeli \ref{wynikiNoiseUnet}. Analizuj¹c jej zawartoœæ
mo¿na dojœæ do wniosku, ¿e warianty sieci UNet lepiej radz¹ sobie z
klasyfikacj¹ sygna³ów zaszumionych w porównaniu do algorytmu Pan-Tompkinsa.
Modele UNet wykaza³y du¿o wiêksz¹ iloœci¹ szczytów poprawnie zaklasyfikowanych
(TP), mniejsz¹ liczb¹ pominiêtych za³amków (FN) oraz, w przypadku wariantu
trenowanego na zbiorze zaszumionym, ni¿sz¹ liczb¹ fa³szywych trafieñ (FP).

Uzyskane rezultaty sugeruj¹ przewagê modeli UNet nad zastosowanym algorytmem
Pan-Tompkinsa w przypadku zaszumionych sygna³ów. Na cele tego eksperymentu
zdecydowano siê na ocenê sygna³u zawieraj¹cego oko³o 300 szczytów, niemniej
jednak, aby uzykaæ bardziej kompleksow¹ ocenê skutecznoœci zastosowanych metod,
nale¿a³oby zebraæ oraz rêcznie oznaczyæ znacznie wiêksz¹ próbê danych.

\begin{table}[ht]
    \captionsetup{justification=centering}
    \caption{Wyniki wariantów sieci UNet oraz algorytmu Pan-Tompkins wzglêdem rêcznie wyznaczonych etykiet na fragmencie sygna³u (zaokr¹glone do 3 miejsc dziesiêtnych)}
    \centering
    \begin{tabular}{|l|c|c|c|}
        \hline
        \multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{\textbf{Pan-Tompkins}} & \multicolumn{1}{l|}{\textbf{MIT-BIH}} & \multicolumn{1}{c|}{\textbf{MIT-BIH Noise Stress}} \\
        \hline
        TP                     & $212$                                        & $272$                                   & 276                                                \\
        \hline
        FP                     & $4$                                          & $5$                                     & 2                                                  \\
        \hline
        FN                     & $77$                                         & $17$                                    & 13                                                 \\
        \hline
        Recall                 & $0.734$                                      & $0,941$                                 & 0,955                                              \\
        \hline
        Precision              & $0.981$                                      & $0,982$                                 & 0,993                                              \\
        \hline
        F1                     & $0.840$                                      & $0,961$                                 & 0,974                                              \\
        \hline
    \end{tabular}
    \label{wynikiNoiseUnet}
\end{table}

\FloatBarrier
\subsection{Wnioski}
Zastosowane warianty sieci UNet oraz algorytm Pan-Tompkinsa uzyska³y œwietn¹
skutecznoœæ w rozpoznawaniu szczytów R w sygna³ach dobrej jakoœci, wykazuj¹c
marginalne ró¿nice miedzy dokonywanymi klasyfikacjami. Wiêksze odchy³y w
wynikach zauwa¿ono podczas analizy sygna³ów mniej idealnych, gdzie lepsze
rezultaty uzyska³y oba przetrenowane modele sieci neuronowych.

W praktycznych zastosowaniach niemal niemo¿liwe jest uzyskanie sygna³u
ca³kowicie pozbawionego szumów. Na podstawie tej obserwacji oraz uzyskanych
wyników mo¿na stwierdziæ, ¿e w przypadku analizy sygna³u EKG pochodz¹cego z
czujnika Polar H10 lepszym wyborem jest zastosowanie modelu UNet
przetrenowanego na zaszumionym zbiorze danych. Model ten wykaza³ porównywaln¹
dok³adnoœæ z innymi metodami w przypadku sygna³ów wysokiej jakoœci, a
jednoczeœnie znacznie lepsz¹ skutecznoœæ w analizie sygna³ów o ni¿szej jakoœci.

